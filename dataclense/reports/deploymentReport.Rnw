\documentclass[10pt,a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{include/tabu/tabu}

<<setup,include=FALSE>>=

opts_chunk$set(           
   dev="pdf", 
   fig.path="figure/manual-",
   fig.lp = "",
   out.width=".9\\textwidth",
   fig.keep="high",
   fig.show="hold",
   fig.align="center",
   fig.width=6.5,
   fig.height=3.5,
   comment=NA)



opts_chunk$set(aliases=c(h='fig.height', w='fig.width',
                 cap='fig.cap', scap='fig.scap'))


## #opts_chunk$set(fig.align='center', w=4.5, h=3.5, fig.show='hold', fig.pos='htbp', par=TRUE, tidy=FALSE)   
#opts_chunk$set(fig.align='center', fig.width=6.5, fig.height=3.5, fig.show='hold', fig.pos='tb', par=TRUE, tidy=FALSE)   

## # this allows for code formatting inline.  
## knit_hooks$set(inline = function(x) {
##    if (is.numeric(x)) return(knitr:::format_sci(x, 'latex'))
##    x = as.character(x)
##    h = knitr:::hilight_source(x, 'latex', list(prompt=FALSE, size='normalsize', highlight=FALSE))
## #   h = gsub("([_#$%&])", "\\\\\\1", h)
## #   h = gsub('(["\'])', '\\1{}', h)
##    gsub('^\\\\begin\\{alltt\\}\\s*|\\\\end\\{alltt\\}\\s*$', '', h)})
## par(las = 1)
## options(width = 90, scipen = 6, digits = 3)

@ 

<<initR, include=FALSE>>=
require(lubridate)
require(reshape)
require(plyr)
require(RMySQL)
require(ggplot2)
require(RColorBrewer)
require(scales) 
require(xtable)
@ 

<<initdb, include=FALSE>>=
#Setup Database Connection
THEDB <- "transferTest"
drv <- dbDriver("MySQL")
#con <- dbConnect(drv,dbname="mainStore",user="chuser")
con <- dbConnect(drv,dbname=THEDB,user="chuser")

# ========================================
#
# Deal with the house itself
#
# ========================================

houses <- dbReadTable(con,"House")
hId <- 5
thisHouse <- houses[hId,]
print(thisHouse)
hAdd <- thisHouse$address


thisHouse$sd <- tryCatch({as.POSIXlt(thisHouse$startDate,tz="GMT")},
                        error=function(e){
                          NA
                        }
                        )

thisHouse$ed <- tryCatch({as.POSIXlt(thisHouse$endDate,tz="GMT")},
                        error=function(e){
                          NA
                        }
                        )
@ 

<<calib, include=FALSE, cache=TRUE>>=
# ========================
#
#  FETCH CALIBRATION STUFF
#
# ========================

##Get Calibration and other such stuff
calibrationData <- dbReadTable(con,"Sensor")

sensorType <- dbReadTable(con,"SensorType")
sensorType <- subset(sensorType,select=c(id,name,units))

##Sensors we are interested in (For Yield Calculateions)
sensorTypeList <- subset(sensorType,
                         name=="Temperature" |
                         name=="Humidity" |
                         name=="Light PAR" |
                         name=="Light TSR" |
                         name=="CO2" |
                         name=="Air Quality" |
                         name=="VOC" |                        
                         name=="Power" |
                         name=="Power pulses"
                         )


@ 

<<fetchData, cache=TRUE, include=FALSE>>=
# ===========================================
#
# Locations for the house we are working with
#
# ============================================

#Fetch Locations Associated with this house
locQry <- paste(" SELECT * FROM Location as L ",
                " LEFT OUTER JOIN Room as R ",
                " ON L.roomId = R.id ",
                " WHERE houseId = ",
                thisHouse$id,
                sep="")

locations <- dbGetQuery(con,statement=locQry)

locIds <-  paste(locations$id,collapse=",")

# ============================================
#
# Data
#
# =============================================

dataQry <- paste("SELECT * from Reading ",
                 " WHERE locationId IN (",
                 locIds,
                 ")",
                 " AND type IN (",
                 paste(sensorTypeList$id,collapse=","),
                 ")",
                 " ORDER BY time",
                 sep="")

theData <- dbGetQuery(con,statement=dataQry)
theData$ts <- as.POSIXct(theData$time,tz="GMT")
theData$Date <- as.Date(theData$ts)
@ 

<<calibrateAndLocs, cache=TRUE, include=FALSE>>=
# ==============================================
#
# Calibrate and update locations
#
# ==============================================

#Merge to get the sensors types
tmp <- merge(theData,sensorType,by.x=c("type"),by.y=c("id"),all.x=TRUE)

#And Locations
locList <- subset(locations,select=c(id,name))
names(locList) <- c("id","location")

tmp <- merge(tmp,locList,by.x=c("locationId"),by.y=c("id"),all.x=TRUE)

#and calibrate
calib <- merge(tmp,calibrationData,by.x=c("nodeId","type"),by.y=c("nodeId","sensorTypeId"),all.x=TRUE)

#Where no value is available
calib$calibValue <- calib$value

dataStart <- min(theData$ts)
dataEnd <- max(theData$ts)
dateRange <- interval(dataStart,dataEnd)
expectedSamples <- dateRange %/% minutes(5)
@ 

\title{Deployment Report: \Sexpr{thisHouse[['address']]}}

\begin{document}
\maketitle
\section{Deployment Overview}
This section gives an overview of the deployment.
First  a summary of the deployment is given, the next section gives details of
the nodes included in the deployment and the location these nodes were
placed. Finally the section concludes with a summary of node yield.

%First we need to gather all the data

\subsection{Data Summary}
\begin{description}
\item[Deployment Id:] \Sexpr{thisHouse[['id']]}
\item[DB Start Date] \Sexpr{thisHouse[['startDate']]}
\item[DB End Date] \Sexpr{thisHouse[['endDate']]}
\item[Data Start Date] \Sexpr{dataStart}
\item[Data End Date] \Sexpr{dataEnd}
\item[Data Length] \Sexpr{as.period(dateRange)} Days
\end{description}

\clearpage
\subsection{Node Summary}
Table \ref{tab:nodeLoc} gives details of all deployed nodes and their locations.

<<sumTable,echo=FALSE,results='asis'>>=
nodeSum <- ddply(calib,
                 .(nodeId,location),
                 summarise,
                 count = length(unique(type)))

names(nodeSum) <- c("Node Id","Location","Sensors")
print(xtable(nodeSum,align="lXXX",caption="Summary of Node Locations",label="tab:nodeLoc"),tabular.environment="tabu",include.rownames=FALSE)
@ 

\clearpage
\subsection{Yield Summary}
This next section gives details of the node yield. 
This is expressed as a percentage of the total expected samples per node
received and stored at the base station. 

<<yieldCalcs,include=FALSE>>=
nodeSum <- ddply(calib,
                 .(nodeId,location,type),
                 summarise,
                 count = length(ts),
                 numsensors = length(unique(type)))

#Yield
nodeSum$yield = (nodeSum$count / expectedSamples) * 100.0
avgYield = mean(nodeSum$yield)

#Table of outputs
yieldTable <- ddply(nodeSum,
                    .(nodeId,location),
                    summarise,
                    Yield = mean(yield))

#Heatmap
yieldHeatmap <- ddply(calib,
                    .(nodeId,location,Date),
                    summarise,
                    count = length(ts),
                    numsensors = length(unique(type)))

yieldHeatmap$yield <- yieldHeatmap$count / (288 * yieldHeatmap$numsensors) * 100

#Days with > 90% yield
yieldDays <- ddply(yieldHeatmap,
                   .(Date),
                   summarise,
                   count = sum(count),
                   numsensors = sum(numsensors),
                   avgYield = mean(yield))

yieldDays$yield <- yieldDays$count / (288* yieldDays$numsensors) * 100
totDays <- nrow(yieldDays)
yldDays <- nrow(subset(yieldDays,yield>=90))
@ 


Table \ref{tab:nodeYield} gives an overview of the per node yield. The average
yield for the deployment is \textbf{\Sexpr{avgYield}}. There were
\Sexpr{yldDays} of \Sexpr{totDays} where the yield was above 90\%.

<<yieldTable,echo=FALSE,results='asis'>>=
#Lets format that so its how expected

names(yieldTable) <- c("Node Id","Location","Yield")
print(xtable(yieldTable,align="lXXX",caption="Node Yield Summary",label="tab:nodeYield"),tabular.environment="tabu",include.rownames=FALSE)
@ 

Figure \ref{fig:nodeYield} shows the overall percentage of data collected by
each node.  

<<nodeYield, fig.caption="Per Node Yield", echo=FALSE>>=
#And an Overview Graph
plt <- ggplot(yieldTable,aes(Location,Yield))
plt <- plt+geom_bar(stat="identity",fill="white",color="darkgreen")
plt <- plt+geom_hline(yintercept=90)
plt <- plt+theme_bw()
plt <- plt + opts(axis.text.x=element_text(angle=90))
plt
@ 

Figure \ref{fig:yieldHeatmap} shows the heat map of the daily node yield. The
heatmap can be useful in identifying nodes or periods of low yield.

<<yieldHeatmap, fig.caption="Yield Heatmap", echo=FALSE>>=
#Graph of Yield by Expected vs 

plt <- ggplot(yieldHeatmap,aes(Date,location,fill=yield))
plt <- plt+geom_tile(color="white")
plt
@ 

\cleardoublepage

\section{Data Summaries}
This next section summarises the data collected during the deployment

\subsection{Temperature Data}
Table \ref{tab:tempOverview} gives an overview of temperature data.

<<tempTable,include=FALSE>>=
ss <- subset(calib,type==0)
summary <-  ddply(subset(ss),
                  .(nodeId,location),
                  summarise,
                  avgvalue = mean(calibValue),
                  minvalue = min(calibValue),
                  maxvalue = max(calibValue)
                  )

degC <- expression(paste(" ",degree,"C"))
names(summary) <- c("Node Id","Location","Average","Minimum","Maximum")

print(xtable(summary,align="lXXXXX",caption="Temperature Data Overview",label="tab:tempOverview"),tabular.environment="tabu",include.rownames=FALSE)
@ 

<<tempGraph,fig.cap="Temperature Data Summary",echo=FALSE,fig.label="fig:tempOverview">>=
plt <- ggplot(ss,aes(ts,calibValue,color=factor(nodeId)))
plt <- plt+geom_point()
plt <- plt+xlab("Date") + ylab("Temperature")
plt <- plt + theme_bw(base_size=8)
plt <- plt+geom_vline(aes(xintercept=as.numeric(thisHouse$sd)))
plt <- plt+geom_vline(aes(xintercept=as.numeric(thisHouse$ed)))
plt + facet_grid(location~.)
@ 

%Comfort Exposure
<<comfortCalcs>>=
ss <- subset(calib,type==0)

#Table of values that we are using
summary <-  ddply(subset(calib,type==0),
                  .(nodeId,location),
                  summarise,
                  avg = mean(calibValue),
                  mode = Mode(calibValue),
                  min = min(calibValue),
                  max = max(calibValue))

#Testing Plot
#plt <- ggplot(ss)
#plt <- plt + geom_line(aes(ts,calibValue,color=nodeId))

tempLabels = c("Health Risk","Cold","Comfortable","Warm","Overheating")

ss$comfort <- cut(ss$calibValue,breaks=c(0,16,18,22,27,100),
           labels=c("Health Risk <16","Cold 16-18","Comfortable 18-22","Warm 22-27","Overheating 27+"))

#ss$locationLab <- paste(ss$nodeId,"_",ss$location)
ss$locationLab <- ss$location

#Freq for all
foo <- count(ss,vars=c('comfort'))
foo$pc <- foo$freq / sum(foo$freq) * 100.0


## #Give PlyR a go.
## #Count Values
foo <- count(ss,vars=c('locationLab','comfort'))
#Calc Percentages
foo <- ddply(foo,.(locationLab),transform,p=freq/sum(freq))
foo<- ddply(foo,.(locationLab),transform,tpos = cumsum(p) - 0.5*p)

fooLab <- subset(foo,comfort=="Comfortable 18-22")
fooLab$label <- paste(round(fooLab$p * 100 ,digits=2),"%",sep="")
@ 

<<tempComfortGraph,fig.caption="Temperature Exposure Graph">>=
plt <- ggplot(foo,aes(locationLab,p,fill=comfort))
#plt <- ggplot(foo,aes(location,p,fill=comfort))
plt <- plt+geom_bar(stat="identity")
plt <- plt+geom_text(data=fooLab,aes(locationLab,tpos,label=label))
#plt <- plt+geom_text(aes(label=comfort,y=count),size=3,position="stack")
#plt <- plt+geom_text(aes(label=p,y=freq),size=3,position="stack")
plt <- plt+scale_fill_manual("Comfort Level",values=rev(brewer.pal(n=6, "RdYlBu")))
plt <- plt+xlab("Room")
plt <- plt+ylab("Percentage of samples at this level")
plt <- plt+theme_bw()
plt <- plt+coord_flip()
plt
@ 

\end{document}
